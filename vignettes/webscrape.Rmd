---
title: "Webscraping"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{vignette}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

The citationSearch package is a tool used to search citations against
online libraries such as Treesearch, Agricola, Bureau of Land Management and
National Forest Service Library.

With the exception of the Agricola site, 
there is a functionality for downloading every possible search result 
(generally by submitting an empty search). The functions involved in the 
package allows a user to download the full collections so that they could be 
searched locally as well.


Some of the library collections involved are the 
[Treesearch library](https://www.fs.usda.gov/treesearch/), the NSFL library, 
the BLM library, and the Agricola collection.

This vignette introduces basic concepts to get started with citationSearch.


To begin, we first need to load the citationSearch package. 
```{r setup, warning=FALSE}
library(citationSearch)
```

# Treesearch
-----------
`treesearch_web_query()` queries the 
[Treesearch website](https://www.fs.usda.gov/treesearch/) 
(under the United States Department of Agriculture) with a given search
parameter. It accepts the following parameters: *keywords* (all fields) or 
*title*, *author last name*, *date range*, *FS station*, *FS series*, and/or 
*volume*. Running the function will returns a dataframe of titles, the 
treesearch id, and  text of the top 20 results. 

`treesearch_get_metadata_one()` takes in a string of any treesearch ID and 
returns a dataframe of the information on each entry.

```{r}
res <- treesearch_web_query(
    keywords = "increment-borer methods fire history", authorlastname <- "Arno")
res
```


`treesearch_get_metadata_all()` takes in no parameters, which will return a 
dataframe containing metadata for all items in the treesearch catalog.

```{r, eval=FALSE}
treesearch_all_metadata <- treesearch_get_metadata_all()
```

# Agricola
------------

`agricola_query()` queries the two 
[NAL Agricola databases](https://agricola.nal.usda.gov/vwebv/selectDatabase.do?dbCode=AGRI2DB&dbCode=LOCAL) 
(journal articles and other materials) with a given search parameter. 
It takes in an RSelenium remote driver object and for the search fields,
it accepts a *title*, *author*, *keyword*, *isbn*, *language*, *publisher*, 
*series*, *subject*, and/or *source.* (_Note: The search can use at most three 
fields. If more are supplied, the function will ignore them._) The query 
function returns dataframe of titles and links.

As mentioned earlier, the function requires the installation of RSelenium 
beforehand, as it takes in a remote driver for it to load correctly. For the 
`remoteDriver()` to open, you can download and run a docker container. 
Running a docker container is a simpler way to load and open the function 
because it removes many of the issues user may have relating to JAVA/browser 
version/selenium version etc. Specifically, we will be using the Docker 
application. You can follow instructions for downloading and running Docker 
[here](https://cran.r-project.org/web/packages/RSelenium/vignettes/docker.html). 

Once you successfully load a Docker server, you can now run the 
`agricola_web_query()` function. This function takes in at most three parameters: 

```{r, eval=FALSE}
library(RSelenium)
rem_dr <- remoteDriver(port = 4445L)
rem_dr$open(silent = TRUE)

res <- agricola_query(rem_dr, 
    title = "Biological soil crusts: Ecology and management", 
    author = "Jayne Belnap")
```

`agricola_parse()` takes in a string of any agricola ID and returns a 
dataframe of the information on each entry.

```{r, eval=FALSE}
docs <- lapply(res$link, agricola_parse)
agricola_all <- data.frame(do.call("rbind", docs))
```

# National Forest Service Library (NFSL)
--------

`nfsl_query()` queries the 
[National Forest Service Library] <https://nfsl.contentdm.oclc.org/digital/api/collections/> 
with the given search parameters *title*, *creators*, *publisher*, 
*contributors*, *date*, *identifier*, and/or *source* and returns a dataframe 
containing the titles and links of each entry.

`nfsl_parse` takes each blm ID string, scrapes each NFSL page with the link,
and returns a dataframe of the information on each entry.

The following is an example search for NFSL:
```{r}
res <- nfsl_query(creators = c("arno", "tomback"))
res
```

`nfsl_get_metadata_all()` scrapes the NFSL website with each ID and returns a 
dataframe with information on all entries on the website. The function takes 
around 2 hours to run.

```{r, eval=FALSE}
nfsl_data <- nfsl_get_metadata_all()
```

# Bureau of Land Management Library (BLM)
--------

`blm_query` queries the 
[Bureau of Land Management Library] <https://archive.org/details/blmlibrary?>. 
It accepts the following parameters: *query*, *years*, *mediatypes*, *subjects*,
*creators*, and/or *languages*. 
Running the function returns a dataframe of the information of the top 75 
results of each search.

`blm_parse` takes each blm ID string, scrapes BLM website with the ID, 
and returns a dataframe of the information on each entry.

The following is an example search for BLM:
```{r}
res <- blm_query(query = "wildlife", subjects = c("Wildlife conservation", "land"))
res
```

`blm_get_metadata_all()` scrapes the following site 
<https://archive.org/services/search/v1/scrape?fields=title&q=collection%3Ablmlibrary> 
for identifier and title of each entries, scrapes the BLM website with each ID,
and returns a dataframe with information on all entries on the website. 
The function takes around 1 hour to run. 

```{r, eval=FALSE}
blm_data <- blm_get_metadata_all()
```
